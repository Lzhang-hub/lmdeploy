{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=4,5,6,7\n",
    "from lmdeploy import pipeline, GenerationConfig, TurbomindEngineConfig\n",
    "import json\n",
    "\n",
    "\n",
    "model_path=\"/chubao/tj-train-ssd-21/wanghaotian/scripts/LLaMA-Factory/saves/qwen2-72B/qwen2_72b_dashu_v5_231w_func/checkpoint-4678\"\n",
    "backend_config = TurbomindEngineConfig(tp=4)\n",
    "gen_config = GenerationConfig(top_p=0.8,\n",
    "                              top_k=1,\n",
    "                              temperature=0.8,\n",
    "                              max_new_tokens=1024)\n",
    "pipe = pipeline(model_path,\n",
    "                backend_config=backend_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sys and promt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "func_list=[\n",
    "            {\"id\":\"456\",\n",
    "            \"type\": \"function\",\n",
    "            \"function\":{\n",
    "                'name': 'generate_invoice', \n",
    "                'description': '生成发票', \n",
    "                'parameters': {\n",
    "                    'type': 'object', \n",
    "                    'properties': {\n",
    "                        'customer_name': {\n",
    "                            'type': 'string', 'description': '客户名称'\n",
    "                        }, \n",
    "                        'items': {\n",
    "                            'type': 'array', \n",
    "                            'items': {\n",
    "                                'type': 'object', \n",
    "                                'properties': {\n",
    "                                    'name': {\n",
    "                                        'type': 'string', 'description': 'The item name'\n",
    "                                    }, \n",
    "                                    'quantity': {\n",
    "                                        'type': 'integer', 'description': 'The quantity of the item'\n",
    "                                    }, \n",
    "                                    'price': {\n",
    "                                        'type': 'number', 'description': 'The price per unit'\n",
    "                                    }\n",
    "                                }, \n",
    "                            'required': ['name', 'quantity', 'price']\n",
    "                            }\n",
    "                        }\n",
    "                    }, \n",
    "                    'required': ['customer_name', 'items']\n",
    "                }\n",
    "            }\n",
    "            },\n",
    "            {\"id\":\"123\",\n",
    "            \"type\": \"function\",\n",
    "            \"function\":{'name': 'generate_password', 'description': '生成随机密码', 'parameters': {'type': 'object', 'properties': {'length': {'type': 'integer', 'description': '密码的长度'}}, 'required': ['length']}}}\n",
    "]\n",
    "\n",
    "# func_list=[\n",
    "#         {   \"id\":\"456\",\n",
    "#             \"type\": \"function\",\n",
    "#             \"function\": {\n",
    "#                 \"name\": \"current_time\",\n",
    "#                 \"description\": \"返回当前事件\",\n",
    "#                 \"parameters\": {}\n",
    "#             }\n",
    "#         }\n",
    "#     ]\n",
    "\n",
    "system = \"\"\"You are a helpful assistant.You have access to the following functions:\n",
    "{functions}\n",
    "If a you choose to call a function ONLY reply in the following format:\n",
    "{start_tag}{function_name}{parameters}{end_tag}\n",
    "where:\n",
    "start_tag => `<functioncall>`\n",
    "function_name => name of the function\n",
    "parameters => a JSON dict with the function argument name as key and function argument value as value.\n",
    "end_tag => `</functioncall>`\n",
    "\n",
    "Here is an example:\n",
    "<functioncall> eaxmple_function_name {\"example_arguments\": \"example_value\"} </functioncall>\n",
    "\n",
    "Reminder:\n",
    "- Function calls MUST follow the specified format\n",
    "- Required parameters MUST be specified\n",
    "- Only call one function at a time\n",
    "- Put the entire function call reply on one line\n",
    "- Always add your sources when using search results to answer the user query\n",
    "\"\"\"\n",
    "sys_input = system.replace(\"{functions}\", \"\\n\".join([json.dumps(x, ensure_ascii=False) for x in func_list]))\n",
    "\n",
    "prompt=\"我需要为John Doe生成一张发票。他购买了2个苹果，每个$1，以及3根香蕉，每根$0.5。\"\n",
    "# prompt = \"现在是几点?\"\n",
    "print(sys_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解析函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "from lmdeploy.serve.openai.protocol import (  # noqa: E501\n",
    "    ChatCompletionRequest, ChatCompletionResponse,\n",
    "    ChatCompletionResponseChoice, ChatCompletionResponseStreamChoice,\n",
    "    ChatCompletionStreamResponse, ChatCompletionTokenLogprob, ChatMessage,\n",
    "    ChoiceLogprobs, CompletionRequest, CompletionResponse,\n",
    "    CompletionResponse, CompletionResponseChoice,\n",
    "    CompletionResponseStreamChoice, CompletionStreamResponse, DeltaMessage,\n",
    "    EmbeddingsRequest, EncodeRequest, EncodeResponse, ErrorResponse,\n",
    "    FunctionResponse, FunctionStreamResponse,GenerateRequest, GenerateResponse,\n",
    "    LogProbs, ModelCard, ModelList, ModelPermission, ToolCall, TopLogprob,\n",
    "    UsageInfo,ToolCallStream,FunctionResponse)  \n",
    "import dataclasses\n",
    "from typing import AsyncGenerator, Dict, List, Literal, Optional, Union\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class UnmarshalRes:\n",
    "    response_json: str\n",
    "    first_return: bool\n",
    "    last_return: bool\n",
    "    name: str\n",
    "    action_id: int \n",
    "def create_stream_response_json(\n",
    "        index: int,\n",
    "        text: str,\n",
    "        tool_calls: Optional[List[ToolCall]],\n",
    "        finish_reason: Optional[str] = None,\n",
    "        logprobs: Optional[LogProbs] = None) -> str:\n",
    "    choice_data = ChatCompletionResponseStreamChoice(\n",
    "        index=index,\n",
    "        delta=DeltaMessage(role='assistant', content=text,tool_calls=tool_calls),\n",
    "        finish_reason=finish_reason,\n",
    "        logprobs=logprobs)\n",
    "    response = ChatCompletionStreamResponse(\n",
    "        id=\"1\",\n",
    "        created=\"1\",\n",
    "        model=\"test\",\n",
    "        choices=[choice_data]\n",
    "    )\n",
    "    response_json = response.model_dump_json()\n",
    "\n",
    "    return response_json\n",
    "\n",
    "def unmarshal_llama3_1_tool(res,tmp_prefix_result,first_return,last_return,name,action_id,logprobs):\n",
    "        if res.finish_reason == 'stop':\n",
    "            res.finish_reason = 'tool_calls'\n",
    "        # print(tmp_prefix_result)\n",
    "        \n",
    "        if '<functioncall>' in tmp_prefix_result and ' {' in tmp_prefix_result:   \n",
    "            if name==\"\":\n",
    "                name = tmp_prefix_result.split('<functioncall> ')[1].split(' {')[0]\n",
    "                action_id = [tool['function']['name'] for tool in func_list].index(name)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        if not first_return:\n",
    "            fisrt_arguments=tmp_prefix_result.split(name+' ')[1]\n",
    "            tool_calls = [\n",
    "                ToolCall(index=str(action_id),\n",
    "                    id=str(action_id),\n",
    "                    function=FunctionResponse(name=name,arguments=fisrt_arguments))]\n",
    "            response_json = create_stream_response_json(\n",
    "                    index=0,\n",
    "                    text='',\n",
    "                    tool_calls=tool_calls,\n",
    "                    finish_reason=res.finish_reason,\n",
    "                    logprobs=logprobs)\n",
    "            first_return=True\n",
    "        elif not last_return:\n",
    "            if tmp_prefix_result.endswith(' </'):\n",
    "                tool_response=res.text.split(' </')[0]\n",
    "                tool_calls = [\n",
    "                    ToolCallStream(index=str(action_id),function=FunctionStreamResponse(arguments=tool_response))]\n",
    "                response_json = create_stream_response_json(\n",
    "                        index=0,\n",
    "                        text='',\n",
    "                        tool_calls=tool_calls,\n",
    "                        finish_reason=res.finish_reason,\n",
    "                        logprobs=logprobs)\n",
    "                last_return=True\n",
    "            else:\n",
    "                # if tmp_prefix_result.endswith(' {\"'):\n",
    "                #     res.text='{\"'+res.text\n",
    "                tool_calls = [\n",
    "                    ToolCallStream(index=str(action_id),function=FunctionStreamResponse(arguments=res.text))]\n",
    "                response_json = create_stream_response_json(\n",
    "                        index=0,\n",
    "                        text='',\n",
    "                        tool_calls=tool_calls,\n",
    "                        finish_reason=res.finish_reason,\n",
    "                        logprobs=logprobs)\n",
    "        else:\n",
    "            response_json = create_stream_response_json(\n",
    "                    index=0,\n",
    "                    text=None,\n",
    "                    tool_calls=None,\n",
    "                    finish_reason=res.finish_reason,\n",
    "                    logprobs=logprobs)\n",
    "        return UnmarshalRes(response_json,first_return,last_return,name,action_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 访问测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": sys_input\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "init_unmarshal=UnmarshalRes(\"\",False,False,\"\",None)\n",
    "tmp_prefix_result=\"\"\n",
    "accumulated_result=\"\"\n",
    "for item in pipe.stream_infer(messages, gen_config=gen_config):\n",
    "    tmp_prefix_result += item.text\n",
    "    logprobs, usage = None, None\n",
    "    model_unmarshal_res=unmarshal_llama3_1_tool(item,tmp_prefix_result,init_unmarshal.first_return,init_unmarshal.last_return,init_unmarshal.name,init_unmarshal.action_id,logprobs)\n",
    "    if model_unmarshal_res!=None:\n",
    "        response_json=model_unmarshal_res.response_json\n",
    "        init_unmarshal=model_unmarshal_res\n",
    "    else:\n",
    "        continue\n",
    "    res_josn=json.loads(model_unmarshal_res.response_json)\n",
    "    print(res_josn)\n",
    "    if res_josn['choices'][0]['delta']['tool_calls']!=None:\n",
    "        if 'id' in res_josn['choices'][0]['delta']['tool_calls'][0]:\n",
    "            res_tool=res_josn['choices'][0]['delta']['tool_calls'][0]['function']\n",
    "            accumulated_result=accumulated_result+res_josn['choices'][0]['delta']['tool_calls'][0]['function']['arguments']\n",
    "        else:\n",
    "            res_tool=res_josn['choices'][0]['delta']['tool_calls'][0]['function']['arguments']\n",
    "            accumulated_result=accumulated_result+res_josn['choices'][0]['delta']['tool_calls'][0]['function']['arguments']\n",
    "print(accumulated_result)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
